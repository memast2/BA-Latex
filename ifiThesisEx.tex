\documentclass[abstracton,12pt]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{times}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{url}
\usepackage{chapterbib}
\usepackage{gensymb}
\usepackage{BTree}
\usepackage{weiwBTree}
\usepackage{float}
\usepackage{array}
\usetikzlibrary{shapes, calc}




% --------- 
\lstset{
	language=C,                % choose the language of the code
	numbers=right,                   % where to put the line-numbers
	stepnumber=1,                   % the step between two line-numbers.        
	numbersep=6pt,                  % how far the line-numbers are from the code
	backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
	showspaces=false,               % show spaces adding particular underscores
	showstringspaces=false,         % underline spaces within strings
	showtabs=false,                 % show tabs within strings adding particular underscores
	tabsize=2,                      % sets default tabsize to 2 spaces
	captionpos=b,                   % sets the caption-position to bottom
	breaklines=true,                % sets automatic line breaking
	breakatwhitespace=true,         % sets if automatic breaks should only happen at whitespace
	title=\lstname,                 % show the filename of files included with \lstinputlisting;
}

\setlength{\parindent}{0pt} 


\titlehead{Department of Informatics, University of Zürich}
\subject{\vspace*{2cm}BSc Thesis}
\title{Implementing an Index Structure for Streaming Time Series Data}
\author{
  Melina Mast\\[-5pt]
  \scriptsize Matrikelnummer: 13-762-588\\[-5pt]
  \scriptsize Email: \texttt{melina.mast@uzh.ch}
}
\date{\vspace*{2cm}August, 2016}
\publishers{
  \small supervised by Prof.\ Dr.\ Michael Böhlen and Kevin Wellenzohn \\[5cm]
  \begin{tikzpicture}[overlay]
    \node at (-3,-3) {\includegraphics[height=5.5cm]{IFIlogo}};
    \node at (7,-3) {\includegraphics[height=2cm]{dbtgBW}};
  \end{tikzpicture}
}

%----\dedication{dedicated to xxx}

% --------- 

\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newenvironment{proof}
  {\noindent{\bf Proof:\rm}}{\hfill$\Box$\vspace{\medskipamount}}

\def\bbbr{{\rm I\!R}}
\def\bbbm{{\rm I\!M}}
\def\bbbn{{\rm I\!N}}
\def\bbbz{{\rm I\!Z}}

% --------- 

\begin{document}

\maketitle

\chapter*{Acknowledgements}



\begin{abstract}
  ...
\end{abstract}

\chapter*{Zusammenfassung}

\tableofcontents
\listoffigures
\listoftables
\renewcommand{\lstlistingname}{Algorithm}% Listing -> Algorithm

\listofalgorithms
\addtocontents{loa}{\def\string\figurename{Algorithm}}

\chapter{Introduction}
A streaming time series \(s\) is a unbounded sequence of data points that is continuously extended, potentially forever. Streaming time series are relevant to applications in diverse domains for example in finance, meteorology or sensor networks. All domains have applications that need to be fed continuously with the latest data e.g. the financial stock market or the weather information. But the processing of large volumes of time series data is impractical. A system can only keep a limited size of data in main memory.\\
Since streaming time series are unbounded, a system cannot hold the constantly generated data in his main memory endlessly. Therefore, the data that is kept in main memory needs to be limited to just a portion of the streaming time series. Besides, in order to be practical for a application like the financial stock market, the data that arrives in a defined time interval (e.g. every 2 minutes) needs to be completely processed until the succeeding data arises.\\
The thesis presents a way to implement the described data structures after discussing the requirements. Furthermore, it documents the out coming experimental results.
In the end of the thesis, in Chapter \ref{sec:Summary}, the findings will be summarized and concluded.

\section{Thesis Outline}
...First...

\chapter{Background and Related Work}
Time series data is not always gapless. E.g. due to sensor failures or transmission errors values can get missing. But since many applications need complete data before further data processing is possible, the missing values need to be recovered first. \\The paper \emph{Continuous Imputation of Missing Values in Highly Correlated Streams of Time Series Data} \cite{BScT} presents a two-dimensional query pattern over the most recent values of a set of time series. The algorithm was developed in the context of meteorology. The \emph{Südtiroler Beratungsring (SBR)} operates a network of weather stations where each station collects continuously (every five minutes) new temperature data. If a value is missing due to sensor failures or other problems, it will be continuously imputed. The imputation needs to fulfill two main requirements: \\
\begin{itemize}  
	\item The algorithm needs to be efficient enough to complete the data imputation before the new measurement arrives. 
	\item The imputation must rely on past measurements.\\
\end{itemize}
The algorithm provided in the paper is called Top-\emph{k} Case Matching (TKCM) algorithm. It defines a two-dimensional query pattern that contains the measurements of the reference time series in a window of time. It seeks for the \emph{k} patterns that match the query pattern best. The missing value is derived from the \emph{k} past pattern. Therefore, it determines for each \emph{time series} a small set of highly correlated \emph{reference time series}. To scan the entire data set to identify the \emph{k} best is not practical. Hence, only a small portion of the data is scanned. In the following, the data set of the \emph{SBM} is described in Section \ref{sec:DS}. After, the TKCM algorithm presented in \cite{BScT} is introduced. Finally, the connection to the present thesis is made in Section \ref{sec:ImpTKCM} and the implementation is introduced. 


\section{The Data Set}
\label{sec:DS}
The \emph{SBR} operates 115 weather stations in South Tyrol. Each of the weather stations records temperature every five minutes. 8\% of the data set is missing. Missing values often occur in groups either due to transmission problems which lead to smaller missing groups of no more than 5 consecutive missing values or sensor failures which may lead to larger missing groups. 87\% of the missing blocks are small and therefore not more than 5 blocks in length. The algorithm is described in Section \ref{sec:TKCM}. 


\section{TKCM}
\label{sec:TKCM}
The implementation of the index structure described in the following thesis is a fundamental part of the TKCM algorithm.\\
The algorithm is a \emph{k}-Nearest Neighbor Imputation algorithm that uses reference time series to find similar weather situations in the past. \\Let $W=[ \underline{t}, \bar{t} ]$ be a sliding window of length $|W|$. Time $\underline{t}$ stands for the oldest time point that fits into the time window and $\bar{t}$ stands for the current time point for which the stream produced a new value. Besides, consider a set $S = \{s_1,s_2,...\}$ of streaming time series. The value of time series \emph{s} e S at time \emph{t} is denoted as $s(t)$. Only the values in the time window $W$ are kept in main memory. If the current value of the time series is missing we write $s(\bar{t})=NIL$. However, all the time points $t < \bar{t}$ have a time series \emph{s} that is complete. Hence, $\forall t < \bar{t} : s(t) \ne NIL$ since \emph{s} contains imputed values if the real ones were missing. To impute the missing values, reference time series are used. Let $R_s = [r_1, r_2, ...]$ be a sequence of \emph{reference time series} $r_i \in S \setminus \{s\}$ for time series \emph{s}. TKCM chooses for each base time series $s \in S$ the ranked sequence of reference time series $R_s$. The fundamental idea is to search for a co-occurrence for two time points $t$, $\bar{t}$ where the reference time series \emph{r} has values $r(\bar{t})\approx r(t)$, then also $s(\bar{t}) \approx s(t)$. Parameter \emph{l} stands for the number of reference time series that TKCM should consider. $R_s$ is computed using the Case Matching Algorithm further described in the paper. It consists of \emph{l} reference values at time $\bar{t}$. Further, we define $R_s^l$ as the first \emph{l} time series of $R_s$ that have a value $r_i(\bar{t}) \ne NIL$. \\
The two-dimensional query pattern $P_{\bar{t}}$ is defined with \emph{l} reference time series on the spatial dimension and a time window of length \emph{p} on the time dimension.
\newtheorem{defn}{Definition}[section]
\begin{defn}
	Query-Pattern. Let p and o denote the pattern length and pattern offset, respectively, where $p > 1$ and $0 \leq o < p$. Query pattern $P_{\bar{t}}$ contains all values of time series $R_s^l \cup \{s\}$ in the window of time $[\bar{t} - p, \bar{t}]$, except the missing value $s(\bar{t}) = NIL$. $P_{\bar{t}}$ is a set of triples $(r,o,r( \bar{t}-o))$, such that:
	\begin{align*}
P_{\bar{t}}=\{(r,o,r( \bar{t}-o))| r \in \{s\} \cup R_s^l \land 0 \cup 0 \leq o < p\} \ne \{(s,0,s(\bar{t}))\}
	\end{align*}
	The value of a cell is given by $P_{\bar{t}}^{r,o}$, hence $(r, o, P_{\bar{t}}^{r,o}) \in P_{\bar{t}}$.
\end{defn}
\newtheorem{exmp}{Example}[section]
\begin{exmp}
A data example for a triple is $(r_1,0,20.5^{\circ}C)$, where $r_1$ represents the reference values, $0$ is the pattern offset \emph{o} and $20.5^{\circ}C$ represents the degree at time $\bar{t}$. A pattern example for l = 2 and p = 1 would be: $P_{\bar{t}}=\{(r_1,0,20.5^{\circ}C),(r_2,0,19.5^{\circ}C)\}$.
\end{exmp}
The TKCM algorithm searches for the \emph{k} patterns $P_t$ in the time window $W$ that best match the query pattern $P_{\bar{t}}$. The pattern $P_t$ matches the query patter $P_{\bar{t}}$ if for each cell $P_{\bar{t}}^{r,o} \in P_{\bar{t}}$ a corresponding cell  $P_{t}^{r,o} \in P_t$ exists. The error between a pattern $P_t$ and $P_{\bar{t}}$  is the sum of the cell-wise differences in the patterns:
\begin{align*}
\delta(P_{t}, P_{\bar{t}}) = \displaystyle\sum_{P_{\bar{t}}^{r,o} \in P_{\bar{t}}}^{} |P_{t}^{r,o} - P_{\bar{t}}^{r,o}|
\end{align*}
The \emph{k} patterns that minimize $\delta(P_{t}, P_{\bar{t}})$ are matched by the TKCM. Further, their time points \emph{t} is collected in a set $T_k$:
\newcommand*{\argmin}{\operatornamewithlimits{argmin}\limits}
\begin{align*}
T_i = T_{i-1} \cup \{\argmin_{%
	\substack{%
		\text t \in W \\
		\text t \neq \bar{t} \wedge t \notin T_{i-1}
	}
}	\delta(P_{t}, P_{\bar{t}})\}
\end{align*}
The matched time points $T_k$ are used for the imputation. The value $\hat{s}(t)$ that is calculated as the average of the values $\{s(t) | t \in T_k\}$ will be imputed. The calculation is as follows: 
\begin{align*}
\hat{s}(t) = \frac{1}{|T_k|} \displaystyle\sum_{t \in T_k}^{} s(t)
\end{align*}
\begin{exmp}
	If the base time series s has a missing value at time $\bar{t}=20:20$ the value needs to be imputed. The query pattern $P_{\bar{t}}$ is defined in this example with $l=2$ reference time series and pattern length $p=2$. Assumed that the $k=3$ most similar matches are $P_{20:15} = 19.5^{\circ}C$, $P_{20:10}= 19.1^{\circ}C$ and $P_{19:40} = 19.9^{\circ}C$, the computation for $\hat{s}(t)$ is as follows: $\hat{s}(t) = \frac{1}{3}(19.5^{\circ}C + 19.1^{\circ}C + 19.9^{\circ}C) = 19.5^{\circ}C$. Hence, $19.5^{\circ}C$ is imputed for the missing value at time $\bar{t}=20:20$.
\end{exmp}
In conclusion, TKCM is able to calculate an estimation of a missing value in streaming time series data. To achieve this, TKCM uses three parameters, \emph{k, l} and \emph{p}. Parameter \emph{k} represent the number of patterns TKCM matches and collects. In practice $k =[1,40]$ most useful, since the impact of an exceptional outlier is less aggravated. The parameters \emph{l} and \emph{p} define the size of the two dimensional query pattern $P_{\bar{t}}$. The two dimensions are \emph{l} for space and \emph{p} for time. The accuracy of the imputation value increases as both parameters \emph{l,p} increase, because more relevant query patterns can be matched. But the runtime of TKCM increases with large query patterns. Since the missing values often occur in blocks, as described in Section \ref{sec:DS}, the parameters \emph{l} and \emph{p} generally can be set moderately. E.g. 
$l \in [3,5]$ and $p \in [2,6]$ because most of the missing blocks are no more than 5 consecutive values. If 
$p \in [2,6]$, the query pattern $P_{\bar{t}}$ contains at least one past value of the base time series \emph{s} in 87\% of the cases.


\section{Implementing TKCM}
\label{sec:ImpTKCM}
The TKCM must not only insert missing values, but also process the newest arriving values efficiently. Therefore, TKCM must provide an insertion method for new arriving values to insert the new value into the time window $W$. Since the time window has a limited size $|W|$, a old value has to be deleted for the new arriving value. Provided that, the oldest time \emph{t} does not fit in the time window any more if the window is already full. Besides, the most similar base time values for a given value \emph{v} should be efficiently found and returned. \\
The implementation of these requirements is the main topic of the present thesis. Therefore, the implementation of the TKCM is introduced in the following.

\subsection{Methods Definition}
Retrieving the \emph{k} most similar patterns to a query pattern $P_{\bar{t}}$ is the computationally most expensive part of TKCM. \\
TKCM initializes a set $T =\{\}$. The set is filled during execution with all time points \emph{t} for which pattern $P_t$ has already been compared to the query pattern $P_{\bar{t}}$. Besides, TKCM initializes a set $T^*=\{\}$ that contains the \emph{k} time points $t \in T$ that minimize the error $\delta(P_{t}, P_{\bar{t}})$. Therefore, $T^* \subseteq T$ is always true during execution. 
\\TKCM uses two methods for accessing any time series $r \in S$, \emph{random} and \emph{sorted} access. The two methods are defined as follows: 
\begin{defn}
	Random Access. Random access returns value r(t), given time series r and time point t.	
\end{defn}
\begin{defn}
Sorted Access. Sorted access returns the next yet unseen time point $t_s \notin T$ such that the value $r(t_s-o)$ is most similar to a given pattern cell $P_{\bar{t}}^{r,o}$. $t(s)$ is defined as:
\begin{align*}
t_s = \argmin_{t_s \in W \setminus T} |r(t_s-o) - P_{\bar{t}}^{r,o}|
\end{align*}
\end{defn}
After $T$ and $T^*$ is initialized, TKCM iterates until set $T^*$ contains the $k$ time points $t$ that minimize the difference  $\delta(P_{t}, P_{\bar{t}})$. \\Using the sorted access mode, the algorithm loops through the cells $P_{\bar{t}}^{r,o}$, reading the next potential time point $t_s \notin T$. The time point $t_s \notin T$ is added to $T$. The time point $t_s$ has a corresponding patter $P_{t_s}$ which is at least for one pattern cell similar to the query pattern $P_{\bar{t}}$. \\
The random access mode is used to look up the values that pattern $P_{t_s}$ is composed of. After each iteration a threshold $\tau$ is computed. The threshold $\tau$ is a lower-bound on the error $\delta (P_{t^{'}}, P_{\bar{t}})$ for any time point $t^{'}$ that is yet unseen. Therefore, during the execution of the algorithm
$\forall t^{'} \in T : \tau \leq \delta(P_{t^{'}}, P_{\bar{t}}) $ is valid. Informally this significances that the lower-bound is always smaller or equal to the error between pattern $P_{t^{'}}$ and query patter $P_{\bar{t}}$ for all time points $t^{'}$ that are elements of $T$. Once $\forall t \in T^* : \delta(P_{t}, P_{\bar{t}}) \leq \tau$ the algorithm terminates. At the end, $T^*=T_k$. 

\subsection{Data Structures}
The above described access modes can be efficiently performed by combining two data structures. Namely, a $B^+$ tree and a circular array. Each time series $s \in S$ can be implemented as a circular array. The circular array is kept in main memory. It uses random access to look up value $s(t)$ for a given time $t$. Further, TKCM maintains for each time series $s$ a $B^+$ tree that is also kept in main memory. The $B^+$ tree is ideal for sorted access by value and therefore for range queries. Unlike the well known $B^+$tree, where the leaves are just linked to their succeeding leaf, like shown in Figure \ref{fig:tratree}, the leaves are linked to the succeeding as well as the preceding leaf as shown in Figure \ref{fig:sptree}.\\
\begin{figure}[H]
		\centering
		\begin{tikzpicture}[
		scale=0.6,
		every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
		every matrix/.style={cells={scale=0.6}},
		]

		\btreeinodefourx{root}{13}{17}{24}{30};
		\xyshiftx{-50mm}{-20mm}{\btreelnodefourx{n1}{2}{3}{5}{7}}
		\xyshiftx{0mm}{-20mm}{\btreelnodefourx{n2}{14}{16}{}{}}
		\xyshiftx{50mm}{-20mm}{\btreelnodefourx{n3}{19}{20}{22}{}}
		\xyshiftx{100mm}{-20mm}{\btreelnodefourx{n4}{24}{27}{29}{}}
		\xyshiftx{150mm}{-20mm}{\btreelnodefourx{n5}{33}{34}{38}{39}}
		% 
		\foreach \x in {1,2,...,5} { \btreelinkx{root-\x}{n\x} }
		{\linkleavesOnex{n1}{n2} }
		{\linkleavesOnex{n2}{n3} }
		{\linkleavesOnex{n3}{n4} }
		{\linkleavesOnex{n4}{n5} }
		\end{tikzpicture}

	\caption{Traditional $B^+$ tree.}
	\label{fig:tratree}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[
	scale=0.6,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.6}},
	]
		% 
		\btreeinodefourx{root}{24}{}{}{};
		\xyshiftx{-40mm}{-20mm}{\btreeinodefourx{n1}{13}{17}{}{}}
		\xyshiftx{70mm}{-20mm}{\btreeinodefourx{n2}{30}{38}{}{}}
		% 
		\xyshiftx{-100mm}{-40mm}{\btreelnodefourx{n11}{2}{3}{5}{7}}
		\xyshiftx{-55mm}{-40mm}{\btreelnodefourx{n12}{14}{16}{}{}}
		\xyshiftx{-10mm}{-40mm}{\btreelnodefourx{n13}{19}{20}{22}{}}
		\xyshiftx{35mm}{-40mm}{\btreelnodefourx{n21}{24}{27}{29}{}}
		\xyshiftx{80mm}{-40mm}{\btreelnodefourx{n22}{33}{34}{}{}}
		\xyshiftx{125mm}{-40mm}{\btreelnodefourx{n23}{38}{39}{40}{}}
		% 
		\foreach \x in {1,2} { \btreelinkx{root-\x}{n\x} }
		\foreach \x in {1,2,3} { \btreelinkx{n1-\x}{n1\x} }
		\foreach \x in {1,2,3} { \btreelinkx{n2-\x}{n2\x} }
		{\linkleavesx{n11}{n12} }
		{\linkleavesx{n12}{n13} }
		{\linkleavesx{n13}{n21} }
		{\linkleavesx{n21}{n22} }
		{\linkleavesx{n22}{n23} }
		\end{tikzpicture}
	\caption{A $B^+$ tree with its leaves linked to the preceding and succeeding leaf.}
	\label{fig:sptree}
\end{figure}
The implementation of the data structures, as well as the implementation of sorted access and random access, is topic of the present thesis. The requirements and the used data structures are discussed in Chapter \ref{sec:P}. In addition to that, the implementation is described in Chapter \ref{sec:Implementation}, and finally the implementation is evaluated and its experimental results are discussed in Chapter \ref{sec:Experimental}.  


\chapter{Requirements for Implementing an Index Structure for Streaming Time Series Data}
\label{sec:P}
This chapter the requirements that the later described implementation of the index structure must meet are described, in order to be useful for the TKCM algorithm. The operations are introduced in Section \ref{sec:Op}. Further, the data structures are described in Section \ref{sec:das} and finally the ...

\section{Required Operations}
\label{sec:Op}
A streaming time series $s$ is a sequence of data points that is extended continuously for example every 5 minutes and eventually forever. Since streaming time series are unbounded, a system can only keep a portion of a time series in main memory. \cite{BScT} proposes an index structure that meet the requirements for streaming time series data.\\
Let $W=[ \underline{t}, \bar{t} ]$ be a sliding window of length $|W|$. Time $\underline{t}$ stands for the oldest time point that fits into the time window and $\bar{t}$ stands for the newest time point for which the stream produced a new value. \\\\
The system presented in the present thesis that uses the proposed index structure in \cite{BScT}, namely a circular array and a $B+$ tree, needs to efficiently perform on the streaming time series $s$ in a sliding window $|W|$: \\
\begin{itemize}  
	\item shift$(\bar{t}, v)$: add value \emph{v} for the new current time point $\bar{t}$ and remove value \emph{v'} for the time point $\underline{t} - 1$ that just dropped out of time window $W$.
	\item lookup$(t)$: return the value of time series \emph{s} at time \emph{t}, denoted by $s(t)$.
	\item neighbor$(v, T)$: given a value \emph{v} and a set of time points $T$, return the time point $t \in T$ such that $|v-s(t)|$ is minimal.\\
\end{itemize}
The lookup operation can be efficiently performed by the circular array, while the neighbor operation takes advantage of the fact that the leaves of a $B^+$ tree are sorted and, unlike in a traditional $B^+$ tree, interconnected in both directions. \\
Since the system should be integrable in the TKCM algorithm, it needs to be able to handle the Data Set presented in Section \ref{sec:DS}. Therefore, the $B^+$ tree must be capable to deal with duplicate values, because the same temperature value in a streaming time series may occur several times. 

\section{Data Structures}
\label{sec:das}
To efficiently implement the above mentioned operations the system combines two data structures:
a circular array and a $B^+$ tree. In Figure \ref{fig:B+tree planned} the originally proposed data structure in \cite{BScT} is shown. The $B^+$ tree is connected with pointers to the circular array and vice versa. Further, the temperature values are used as keys in the $B^+$ tree. The size of the circular array is defined as $|W| + 1$ since an empty field is used to identify the current update position. The size $|W|$ and the order of the $B^+$ tree, which defines the size of the nodes, are parameters. Hence they can be changed.\\The circular array and the $B^+$ tree are characterized in the following. 

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[
scale=0.7,
every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
every matrix/.style={cells={scale=0.7}},
]
% root node
\xyshift{-20mm}{0mm}{\btreeinodethree{root}{18.6}{}{}};

%
% intermediate nodes
\xyshift{-50mm}{-15mm}{\btreeinodethree{n1}{17.3}{}{}{}}
\xyshift{ 10mm}{-15mm}{\btreeinodethree{n2}{19.2}{19.4}{19.7}}
%
% connecting root to intermediate level nodes
\foreach \x in {1,2} { \btreelink{root-\x}{n\x} }
%
% leaf nodes
\xyshift{-90mm}{-30mm}{\btreelnodethree{n11}{17.2}{}{}}
\xyshift{-60mm}{-30mm}{\btreelnodethree{n12}{17.3}{18.2}{18.3}}
\xyshift{-30mm}{-30mm}{\btreelnodethree{n21}{18.6}{18.8}{}}
\xyshift{ 0mm}{-30mm}{\btreelnodethree{n22}{19.2}{19.3}{}}
\xyshift{ 30mm}{-30mm}{\btreelnodethree{n23}{19.4}{}{}}
\xyshift{ 60mm}{-30mm}{\btreelnodethree{n24}{19.7}{19.7}{19.8}}
%
% connecting intermediate level to leaf nodes
\foreach \x in {1,2}     { \btreelink{n1-\x}{n1\x} }
\foreach \x in {1,2,3,4} { \btreelink{n2-\x}{n2\x} }
%
% leaf pointers
\draw[btlink] ([yshift=+3pt] n11-c.east) -- ([yshift=+3pt] n12-a.west);
\draw[btlink] ([yshift=-3pt] n12-a.west) -- ([yshift=-3pt] n11-c.east);
\draw[btlink] ([yshift=+3pt] n12-c.east) -- ([yshift=+3pt] n21-a.west);
\draw[btlink] ([yshift=-3pt] n21-a.west) -- ([yshift=-3pt] n12-c.east);
\draw[btlink] ([yshift=+3pt] n21-c.east) -- ([yshift=+3pt] n22-a.west);
\draw[btlink] ([yshift=-3pt] n22-a.west) -- ([yshift=-3pt] n21-c.east);
\draw[btlink] ([yshift=+3pt] n22-c.east) -- ([yshift=+3pt] n23-a.west);
\draw[btlink] ([yshift=-3pt] n23-a.west) -- ([yshift=-3pt] n22-c.east);
\draw[btlink] ([yshift=+3pt] n23-c.east) -- ([yshift=+3pt] n24-a.west);
\draw[btlink] ([yshift=-3pt] n24-a.west) -- ([yshift=-3pt] n23-c.east);
%
% circular array
\xyshift{-15mm}{-70mm}{
	\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
		\node[circularptr] (c1)  {}; \&
		\node[circularptr] (c2)  {}; \&
		\node[circularptr] (c3)  {}; \&
		\node[circularptr] (c4)  {}; \&
		\node[circularptr] (c5)  {}; \&
		\node[circularptr] (c6)  {}; \&
		\node[circularptr] (c7)  {}; \&
		\node[circularptr] (c8)  {}; \&
		\node[circularptr] (c9)  {}; \&
		\node[circularptr] (c10) {}; \&
		\node[circularptr] (c11) {}; \&
		\node[circularptr] (c12) {}; \&
		\node[circularptr] (c13) {}; \\
		%
		\node[circularval] (left) {14:15}; \&
		\node[circularval] {14:20}; \&
		\node[circularval] {14:25}; \&
		\node[circularval] {\phantom{14:25}}; \&
		\node[circularval] {13:30}; \&
		\node[circularval] {13:35}; \&
		\node[circularval] {13:40}; \&
		\node[circularval] {13:45}; \&
		\node[circularval] {13:50}; \&
		\node[circularval] {13:55}; \&
		\node[circularval] {14:00}; \&
		\node[circularval] {14:05}; \&
		\node[circularval] (right) {14:10}; \\
	};
}

%
% draw pointers between circular array and B+ tree
\path[btdlink] ([yshift=-2pt] c2.center)  edge[out=90,in=270] ([yshift=2pt] n22-2.center);
\path[btdlink] ([yshift=-2pt] c5.center)  edge[out=90,in=270] ([yshift=2pt] n22-1.center);
\path[btdlink] ([yshift=-2pt] c11.center) edge[out=90,in=270] ([yshift=2pt] n23-1.center);
\foreach \x in
{1,3,6,7,8,9,10,12,13}
{ \path[->] ([yshift=15pt] c\x.center) edge ([yshift=-2pt] c\x.center); }
\foreach \x in
{n11-1,n12-1,n12-2,n21-1,n21-2,n24-1,n24-2,n24-3}
{ \path[->] ([yshift=-15pt] \x.center) edge ([yshift=2pt] \x.center); }
%
% draw borders
\draw[densely dotted] (-11,1.5) rectangle (8,-5.5);
\draw[densely dotted] (-11,-6) rectangle (8,-10);
\node[anchor=south west] at (-11,1.5) {\Large $B^+$ tree};
\node[anchor=north west] at (-11,-10)  {\Large Circular array};
%
% curly brace
\draw [decorate,decoration={brace,mirror,amplitude=10pt}]
([yshift=-5pt] left.south west) -- ([yshift=-5pt] right.south east)
node [black,midway,yshift=-0.9cm] {\large size $|W|+1$};
\end{tikzpicture}
\vspace{2mm}
\caption{Proposed data structures in \cite{BScT}.}
\label{fig:B+tree planned}
\end{figure}

\subsection{Circular Array}
A circular array is used to store the time series data. The data is assorted by time. Further, the time interval is predefined e.g. every 5 minutes a new value arrives.\\The circular array presented in Figure \ref{fig:B+tree planned} has a size of $|W| + 1$. The empty field is used to identify the next update position. Hence, the position where the next arriving value is inserted. In addition to the time, the associated temperature value is stored in the $B^+$ tree and linked with a pointer.\\
But the circular array presented in the present thesis is slightly different. The value must not be associated by a pointer, but can also be directly stored in the circular array. Besides, instead of an empty field to identify the next update position, the position is stored in a variable and updated with every insertion. The circular array is shown in Figure \ref{fig:cat}
\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}[
	scale=0.7,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.7}},
	]

	% circular array
	\xyshift{-15mm}{-70mm}{
		\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
			\node[circularptr] (c1)  {}; \&
			\node[circularptr] (c2)  {}; \&
			\node[circularptr] (c3)  {}; \&
			\node[circularptr] (c4)  {}; \&
			\node[circularptr] (c5)  {}; \&
			\node[circularptr] (c6)  {}; \&
			\node[circularptr] (c7)  {}; \&
			\node[circularptr] (c8)  {}; \&
			\node[circularptr] (c9)  {}; \&
			\node[circularptr] (c10) {}; \&
			\node[circularptr] (c11) {}; \&
			\node[circularptr] (c12) {};  \\
			%
			\node[circularval] (left) {14:10}; \&
			\node[circularval] {14:15}; \&
			\node[circularval] {14:20}; \&
			\node[circularval] {14:25}; \&
			\node[circularval] {13:30}; \&
			\node[circularval] {13:35}; \&
			\node[circularval] {13:40}; \&
			\node[circularval] {13:45}; \&
			\node[circularval] {13:50}; \&
			\node[circularval] {13:55}; \&
			\node[circularval] {14:00}; \&
			\node[circularval] (right){14:05};\\
		};
	}
	% curly brace
	\draw [decorate,decoration={brace,mirror,amplitude=10pt}]
	([yshift=-5pt] left.south west) -- ([yshift=-5pt] right.south east)
	node [black,midway,yshift=-0.9cm] {\large size $|W|$};
	\end{tikzpicture}
	\vspace{2mm}
	\caption{Circular array without pointers to the $B^+$ tree.}
	\label{fig:cat}
\end{figure}

\subsection{$B^+$ Tree}
A $B^+$ tree is able to execute range queries very efficiently because the leaves of a $B^+$ tree are ordered and linked. To perform the \emph{neighbor}$(v,T)$ operation described in Section \ref{sec:Op} even better, the $B^+$ tree we use has its leaves linked in both directions. The Section \ref{structureBtree} describes the genaral structure of a $B^+$ tree. Further, the differences between the $B^+$ tree used in the present thesis and the $B^+$ tree presented in \cite{BTreeBook} are discussed. 

\subsubsection{The Structure of $B^+$ trees}
\label{structureBtree}
A $B^+$ tree is organized in bocks, as implied by its name. All paths from the root to a leaf have the same length, hence it is \emph{balanced}. There are three types of nodes that may exist in a $B^+$ tree: the root, interior nodes and leaves as you can see in Figure \ref{fig:cat}. The parameter \emph{n} determines the size of the blocks in the $B^+$ tree. Hence, the blocks can have maximum \emph{n} search-keys and \emph{n} + 1 pointers, pointing to its child nodes. Every block is between half full and completely full. What can appear in blocks is listed in the following: \\
\begin{itemize}  
	\item The keys in the leaves are sorted from left to right. 
	\item All pointers in a node point to the level below.
	\item The interior nodes use at least $[\frac{n+1}{2}]$ of its \emph{n} + 1 pointers. In the root at least 2 pointers must be used. 
	\item The first pointer in a node where the first key is \emph{K} points to a node and hence a part of the tree where the keys are less than \emph{K}. The second pointer points to a node where the keys are greater than or equal to \emph{K}, as shown in Figure \ref{lessOrEqual}. 
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[
		scale=0.7,
		every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
		every matrix/.style={cells={scale=0.7}},
		]
		% root node
		
		\xyshift{-20mm}{0mm}{\btreeinodethree{root}{18.8}{}{}};
		
		%
		% intermediate nodes
		\xyshift{-50mm}{-15mm}{\btreeinodethree{n1}{17.3}{}{}{}}
		\xyshift{ 10mm}{-15mm}{\btreeinodethree{n2}{18.8}{19.4}{19.7}}
		
		%
		% connecting root to intermediate level nodes
		\foreach \x in {1,2} { \btreelink{root-\x}{n\x} }
		%
		
		\end{tikzpicture}
		\vspace{2mm}
		\caption{Left children keys < 18.8 and right children keys $\leq 18.8$ .}
		\label{lessOrEqual}
	\end{figure}
\end{itemize}
The $B^+$ tree used for the implementation of the streaming time series data is slightly different to the  $B^+$ tree in \cite{BTreeBook}. The required properties are the following: \\
\begin{itemize}  
	\item The search-keys of the $B^+$ tree are the temperature values in the sliding window $W$.
	\item The leaves are linked in both directions to efficiently perform the \emph{neighbor}$(v,T)$ operation.
	\item The leaves are sorted by the temperature values.
	\item The interior nodes have a temperature search-key.
	\item The leaves store the record of the time series data. A record consists of the temperature value and the associated time value.\\ 
\end{itemize}
Due to weather conditions the temperature values in the time window $W$ can occur several times. Therefore, the keys are not unique. Since the temperature values are used as search-keys, the $B^+$ tree must be able to handle duplicate values. Section \ref{allowDV} proposes different possibilities that allow to use duplicate values in a $B^+$ tree. 

\section{Handling Duplicate Values in $B^+$ trees}
\label{allowDV}
This Section informally presents different ideas to allow duplicate values in a $B^+$ tree. Further, it discusses their advantages and disadvantages and compares them to each other. The advantages and disadvantages are valid for the implementation with the programming language C. 

\subsection{Create unique Keys}
A record in the time series consists of a temperature value and a time value. For each time exists just one temperature value. Therefore the idea is to combine both values and hence always have a unique key. \\
There are two different actions if the case occurs where you have to add a record with a key that already exists in the $B^+$ tree. If the leaf is not already full, the record can be added to the existing leaf. But the keys should be reordered according to their temperature. If the leaf has to split the records with equal keys can be separated due to the associated timestamp. If the equal keys are split to different leaves the parent node must new include the same key and the associated timestamp of the first key of the right child leaf. Hence, the two leaves can now still be separated due to the additional ordering with timetamps. The Figure \ref{fig:keyT} illustrates how the above described tree might look. 
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[
	scale=0.7,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.7}},
	]
	% root node
	
	\xyshift{-20mm}{0mm}{\btreeinodethree{root}{18.8; 10:40}{}{}};
	
	%
	% intermediate nodes
	\xyshift{-50mm}{-15mm}{\btreeinodethree{n1}{16.3; 11:10}{18.8; 10:25}{18.8; 10:30}}
	\xyshift{ 10mm}{-15mm}{\btreeinodethree{n2}{18.8; 10:40}{19.4; 12:10}{19.7; 13:30}}
	
	%
	% connecting root to intermediate level nodes
	\foreach \x in {1,2} { \btreelink{root-\x}{n\x} }
	%
	
	\end{tikzpicture}
	\vspace{2mm}
	\caption{Example $B^+$ tree using a new unique key}
	\label{fig:keyT}
	
\end{figure}		

\subsubsection{Advantages and Disadvantages}
\paragraph{$(+)$}
\begin{itemize}  
	\item Implementation is similar to the $B^+$ tree with no duplicate search-keys. 
	\item The \emph{neighbor}$(v,T)$ operation is equally fast as with no duplicate values. 
\end{itemize}
\paragraph{$(-)$}
\begin{itemize}  
	\item The requirement to allow duplicate values is not meet, since duplicates are just avoided by creating a new unique key. 
	\item More memory needed since the interior nodes must be able to include a timestamp. 
	\item Searching a key is slower than in a $B^+$ tree with no duplicates, since the timestamp value and the temperature value of a interior node has to be checked. This slows down a record insertion and deletion in the tree. 
\end{itemize}

\subsection{Associated List}
\label{Associated List}
The idea of this method is to associate a list to the each key that occurs multiple times. So instead of inserting the key again and using another block in the leaf, the new timestamp is just inserted to its associated list. The Figure \ref{fig:ListApp} illustrates the needed modification to the originally presented $B^+$ tree in Figure {fig:B+tree}.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[
	scale=0.7,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.7}},
	]
	
	% leaf pointers
	\draw[btlink] ([yshift=+3pt] n11-c.east) -- ([yshift=+3pt] n12-a.west);
	\draw[btlink] ([yshift=-3pt] n12-a.west) -- ([yshift=-3pt] n11-c.east);
	\draw[btlink] ([yshift=+3pt] n12-c.east) -- ([yshift=+3pt] n21-a.west);
	\draw[btlink] ([yshift=-3pt] n21-a.west) -- ([yshift=-3pt] n12-c.east);
	\draw[btlink] ([yshift=+3pt] n21-c.east) -- ([yshift=+3pt] n22-a.west);
	\draw[btlink] ([yshift=-3pt] n22-a.west) -- ([yshift=-3pt] n21-c.east);
	\draw[btlink] ([yshift=+3pt] n22-c.east) -- ([yshift=+3pt] n23-a.west);
	\draw[btlink] ([yshift=-3pt] n23-a.west) -- ([yshift=-3pt] n22-c.east);
	\draw[btlink] ([yshift=+3pt] n23-c.east) -- ([yshift=+3pt] n24-a.west);
	\draw[btlink] ([yshift=-3pt] n24-a.west) -- ([yshift=-3pt] n23-c.east);
	%
	% leaf nodes
	\xyshift{-90mm}{-30mm}{\btreelnodethree{n11}{17.2}{}{}}
	\xyshift{-60mm}{-30mm}{\btreelnodethree{n12}{17.3}{18.2}{18.3}}
	\xyshift{-30mm}{-30mm}{\btreelnodethree{n21}{18.6}{18.8}{}}
	\xyshift{ 0mm}{-30mm}{\btreelnodethree{n22}{19.2}{19.3}{}}
	\xyshift{ 30mm}{-30mm}{\btreelnodethree{n23}{19.4}{}{}}
	\xyshift{ 60mm}{-30mm}{\btreelnodethree{n24}{19.7}{19.7}{19.8}}
	%
	
	% circular array
	\xyshift{-15mm}{-70mm}{
		\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
			\node[circularptr] (c1)  {}; \&
			\node[circularptr] (c2)  {}; \&
			\node[circularptr] (c3)  {}; \&
			\node[circularptr] (c13) {}; \\
			%
			\node[circularval] (left) {14:15}; \&
			\node[circularval] {14:30}; \&
			\node[circularval] {14:50}; \&
			\node[circularval] (right) {15:10}; \\
		};
	}	
	%
	% draw pointers between circular array and B+ tree
	\path[btlink2] ([yshift=-2pt] c1.center)  edge[out=90,in=270] ([yshift=2pt] n22-2.center);
	
	\end{tikzpicture}
	\vspace{2mm}
	\caption{Temperature value 19.3 occurs four times in time window $W$.}
	\label{fig:ListApp}
\end{figure}
\subsubsection{Advantages and Disadvantages}
\paragraph{$(+)$}
\begin{itemize}  
	\item  The \emph{neighbor}$(v,T)$ operation, after $v$ has been found, is very fast if multiple temperatures associated to the same key must be added to $T$. Because the entire list can be added. 
	\item Searching a key is equally fast as in a $B^+$ tree with no duplicate values. (Not valid for searching  the associated record timestamp)
	\item A new timestamp can be inserted to the end of the list in $O(1)$ and since the time window $W$ slides forward, the value that should be deleted first from the tree, normally, is at the first position in the list. Therefore, a value can be deleted in $O(1)$ from the list as well. 
\end{itemize}
\paragraph{$(-)$}
\begin{itemize}  
	\item The size and capacity of the list has to be stored, which uses more memory. 
	\item Implementation difficulties because the size of an array cannot be dynamically allocated in the programming language C.
	\item If the array grows because a new timestamps needs to be added memory needs to be reallocated. But reallocating memory and copying the original array is expensive. \\
	TODO find better souce than https://en.wikipedia.org/wiki/Linkedlist\\
\end{itemize}
The implementation in the programming language C has the challenge that memory cannot be dynamically allocated for a growing array. But since we need a sort of array we can add a size and capacity variable to the referring record. The structure is shown in Listing \ref{alg:test}.
\begin{algorithm}[H]
\lstinputlisting[label=alg:test, caption=Record structure ]{test.c}
\caption{Possible structure for a record}
\end{algorithm}
But it is still possible that the capacity of the array is reached and therefore memory needs to be reallocated. Besides, if a value is deleted from the array, the other values either have to be moved backwards to fill the empty place or the array has to stay just fragmentary filled. Either way is not ideal for a good performance. \\
Another way to meet the requirements is to use a linked list that contains the timestamps. The advantage against using an array is to add a new element to the linked list without an expensive reallocation of memory. A deletion can be done in $O(1)$ since the first element of the linked list would be the oldest element. But the insertion would cost $O(n)$ because one has to go through the entire list to find the last element. \\
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[
	scale=0.7,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.7}},
	]

	% leaf pointers
	\draw[btlink] ([yshift=+3pt] n11-c.east) -- ([yshift=+3pt] n12-a.west);
	\draw[btlink] ([yshift=-3pt] n12-a.west) -- ([yshift=-3pt] n11-c.east);
	\draw[btlink] ([yshift=+3pt] n12-c.east) -- ([yshift=+3pt] n21-a.west);
	\draw[btlink] ([yshift=-3pt] n21-a.west) -- ([yshift=-3pt] n12-c.east);
	\draw[btlink] ([yshift=+3pt] n21-c.east) -- ([yshift=+3pt] n22-a.west);
	\draw[btlink] ([yshift=-3pt] n22-a.west) -- ([yshift=-3pt] n21-c.east);
	\draw[btlink] ([yshift=+3pt] n22-c.east) -- ([yshift=+3pt] n23-a.west);
	\draw[btlink] ([yshift=-3pt] n23-a.west) -- ([yshift=-3pt] n22-c.east);
	\draw[btlink] ([yshift=+3pt] n23-c.east) -- ([yshift=+3pt] n24-a.west);
	\draw[btlink] ([yshift=-3pt] n24-a.west) -- ([yshift=-3pt] n23-c.east);
	%
	% leaf nodes
	\xyshift{-90mm}{-30mm}{\btreelnodethree{n11}{17.2}{}{}}
	\xyshift{-60mm}{-30mm}{\btreelnodethree{n12}{17.3}{18.2}{18.3}}
	\xyshift{-30mm}{-30mm}{\btreelnodethree{n21}{18.6}{18.8}{}}
	\xyshift{ 0mm}{-30mm}{\btreelnodethree{n22}{19.2}{19.3}{}}
	\xyshift{ 30mm}{-30mm}{\btreelnodethree{n23}{19.4}{}{}}
	\xyshift{ 60mm}{-30mm}{\btreelnodethree{n24}{19.7}{19.7}{19.8}}
	%

	% circular array
	\xyshift{-40mm}{-70mm}{
		\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
			\node[circularptr] (c1)  {}; \\	
			%
			\node[circularval] (left)(right) {14:15}; \\
		};
	}
		% circular array
		\xyshift{-10mm}{-70mm}{
			\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
				\node[circularptr] (c2)  {}; \\	
				%
				\node[circularval] (left)(right) {14:30}; \\
			};
		}	
		
	% circular array
		\xyshift{20mm}{-70mm}{
				\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
					\node[circularptr] (c3)  {}; \\	
					%
					\node[circularval] (left)(right) {14:50}; \\
				};
		}	
			
	
	% draw pointers between circular array and B+ tree
	\path[btlink2] ([yshift=-2pt] c1.center)  edge[out=90,in=270] ([yshift=2pt] n22-2.center);
	% draw pointers for linked list
	\draw[btlink] ([yshift=-10pt] c1.east) -- ([yshift=-10pt] c2.west);
	\draw[btlink] ([yshift=-10pt] c2.east) -- ([yshift=-10pt] c3.west);	
	\end{tikzpicture}
	\vspace{2mm}
	\caption{Singly linked list}
	\label{fig:SinglyLinked}
\end{figure}

Another idea is to use a circular linked list that is interconnected in both directions as you can see in Figure \ref{fig:DoublyLinked}. The insertion and deletion would then just cost $O(1)$. But the additional pointers use more memory than a singly linked list. Hence, there is a trade-off between speed and memory allocation when using a linked list.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[
	scale=0.7,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.7}},
	]
	
	% leaf pointers
	\draw[btlink] ([yshift=+3pt] n11-c.east) -- ([yshift=+3pt] n12-a.west);
	\draw[btlink] ([yshift=-3pt] n12-a.west) -- ([yshift=-3pt] n11-c.east);
	\draw[btlink] ([yshift=+3pt] n12-c.east) -- ([yshift=+3pt] n21-a.west);
	\draw[btlink] ([yshift=-3pt] n21-a.west) -- ([yshift=-3pt] n12-c.east);
	\draw[btlink] ([yshift=+3pt] n21-c.east) -- ([yshift=+3pt] n22-a.west);
	\draw[btlink] ([yshift=-3pt] n22-a.west) -- ([yshift=-3pt] n21-c.east);
	\draw[btlink] ([yshift=+3pt] n22-c.east) -- ([yshift=+3pt] n23-a.west);
	\draw[btlink] ([yshift=-3pt] n23-a.west) -- ([yshift=-3pt] n22-c.east);
	\draw[btlink] ([yshift=+3pt] n23-c.east) -- ([yshift=+3pt] n24-a.west);
	\draw[btlink] ([yshift=-3pt] n24-a.west) -- ([yshift=-3pt] n23-c.east);
	%
	% leaf nodes
	\xyshift{-90mm}{-30mm}{\btreelnodethree{n11}{17.2}{}{}}
	\xyshift{-60mm}{-30mm}{\btreelnodethree{n12}{17.3}{18.2}{18.3}}
	\xyshift{-30mm}{-30mm}{\btreelnodethree{n21}{18.6}{18.8}{}}
	\xyshift{ 0mm}{-30mm}{\btreelnodethree{n22}{19.2}{19.3}{}}
	\xyshift{ 30mm}{-30mm}{\btreelnodethree{n23}{19.4}{}{}}
	\xyshift{ 60mm}{-30mm}{\btreelnodethree{n24}{19.7}{19.7}{19.8}}
	%
	
	% circular array
	\xyshift{-40mm}{-70mm}{
		\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
			\node[circularptr] (c1)  {}; \\	
			%
			\node[circularval] (left)(right) {14:15}; \\
		};
	}
	% circular array
	\xyshift{-10mm}{-70mm}{
		\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
			\node[circularptr] (c2)  {}; \\	
			%
			\node[circularval] (left)(right) {14:30}; \\
		};
	}	
	
	% circular array
	\xyshift{20mm}{-70mm}{
		\matrix [ampersand replacement=\&, outer sep=0pt, matrix anchor=north] (array) {
			\node[circularptr] (c3)  {}; \\	
			%
			\node[circularval] (left)(right) {14:50}; \\
		};
	}	

	% draw pointers between circular array and B+ tree
	\path[btlink2] ([yshift=-2pt] c1.center)  edge[out=90,in=270] ([yshift=2pt] n22-2.center);
	% draw pointers for linked list
	\draw[btlink] ([yshift=-10pt] c1.east) -- ([yshift=-10pt] c2.west);
	\draw[btlink] ([yshift=-10pt] c2.east) -- ([yshift=-10pt] c3.west);
	\draw[btlink] ([yshift=-20pt] c2.west) -- ([yshift=-20pt] c1.east);
	\draw[btlink] ([yshift=-20pt] c3.west) -- ([yshift=-20pt] c2.east);
	%circular links
	\path[btlink2] ([yshift=-20pt] c1.west)  edge[out=200,in=270] ([yshift=-10pt] c3.east);
	\path[btlink] ([yshift=-10pt] c1.west)  edge[out=210,in=270] ([yshift=-20pt] c3.east);
	\end{tikzpicture}
	\vspace{2mm}
	\caption{Doubly, circular linked list}
	\label{fig:DoublyLinked}
\end{figure}


\subsection{Additional Leaves without a Parent Node}
\label{Additional Leaves}
Another idea to handle duplicate values is to add additional leaves to the tree that do not have a parent node. As shown in Figure \ref{fig:noparents}, the node containing the temperature value \emph{18.3} had been split, since the values did no longer fit into one leaf. The value \emph{18.4} would belong into the same leaf as \emph{18.3} but there is no more space. Instead of splitting the leaf, the additional leaf without a parent is filled up. If e.g. a value \emph{18.5} must be inserted the leaf without a parent must be split. The new leaf would again receive a parent and the old leaf including the duplicate values would stay parent-less. \\
\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}[
	scale=0.7,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.7}},
	]
	% root node
	\xyshift{-20mm}{0mm}{\btreeinodethree{root}{18.6}{}{}};
	
	%
	% intermediate nodes
	\xyshift{-50mm}{-15mm}{\btreeinodethree{n1}{17.3}{}{}{}}
	\xyshift{ 10mm}{-15mm}{\btreeinodethree{n2}{19.2}{19.4}{19.7}}
	%
	% connecting root to intermediate level nodes
	\foreach \x in {1,2} { \btreelink{root-\x}{n\x} }
	%
	% leaf nodes
	\xyshift{-110mm}{-30mm}{\btreelnodethree{n11}{17.2}{}{}}
	\xyshift{-80mm}{-30mm}{\btreelnodethree{n12}{17.3}{18.2}{18.3}}
	\xyshift{-45mm}{-30mm}{\btreelnodethree{n13}{18.3}{18.3}{18.4}}
	\xyshift{-10mm}{-30mm}{\btreelnodethree{n21}{18.6}{18.8}{}}
	\xyshift{ 20mm}{-30mm}{\btreelnodethree{n22}{19.2}{19.3}{}}
	\xyshift{ 50mm}{-30mm}{\btreelnodethree{n23}{19.4}{}{}}
	\xyshift{ 80mm}{-30mm}{\btreelnodethree{n24}{19.7}{19.7}{19.8}}
	%
	% connecting intermediate level to leaf nodes
	\foreach \x in {1,2}     { \btreelink{n1-\x}{n1\x} }
	\foreach \x in {1,2,3,4} { \btreelink{n2-\x}{n2\x} }
	%
	% leaf pointers
	\draw[btlink] ([yshift=+3pt] n11-c.east) -- ([yshift=+3pt] n12-a.west);
	\draw[btlink] ([yshift=-3pt] n12-a.west) -- ([yshift=-3pt] n11-c.east);
	\draw[btlink] ([yshift=+3pt] n12-c.east) -- ([yshift=+3pt] n13-a.west);
	\draw[btlink] ([yshift=+3pt] n13-c.east) -- ([yshift=+3pt] n21-a.west);
	
	\draw[btlink] ([yshift=-3pt] n13-a.west) -- ([yshift=-3pt] n12-c.east);
	\draw[btlink] ([yshift=-3pt] n21-a.west) -- ([yshift=-3pt] n13-c.east);

	\draw[btlink] ([yshift=+3pt] n21-c.east) -- ([yshift=+3pt] n22-a.west);
	\draw[btlink] ([yshift=-3pt] n22-a.west) -- ([yshift=-3pt] n21-c.east);
	\draw[btlink] ([yshift=+3pt] n22-c.east) -- ([yshift=+3pt] n23-a.west);
	\draw[btlink] ([yshift=-3pt] n23-a.west) -- ([yshift=-3pt] n22-c.east);
	\draw[btlink] ([yshift=+3pt] n23-c.east) -- ([yshift=+3pt] n24-a.west);
	\draw[btlink] ([yshift=-3pt] n24-a.west) -- ([yshift=-3pt] n23-c.east);
	%
	\end{tikzpicture}
	\vspace{2mm}
	\caption{$B^+$ tree with an additional leaf without a parent. }
	\label{fig:noparents}
\end{figure}
\subsubsection{Advantages and Disadvantages}
\paragraph{$(+)$}
\begin{itemize}  
	\item  The \emph{neighbor}$(v,T)$ operation is equally fast, after $v$ has been found, as with no duplicate values. 
	\item The memory usage is even better if the tree contains leaves with no parent, since the pointer from parent to its child is not needed. 
	\item The memory usage is equal or less than with no duplicate values. 
	\item The deletion of a duplicate value should be equally fast as with no duplicate values in the tree, since the oldest value should be the leftmost duplicate value in a leaf. 
\end{itemize}
\paragraph{$(-)$}
\begin{itemize}  
	\item  Searching a specific record may take long, depending on the number of duplicate temperature values to the left side of the record. 
\end{itemize}

\subsection{Null Values in Interior Nodes}
\label{Null Values}
The book \emph{Database Systems - The Complete Book} \cite{BTreeBook} presents an additional approach to handle duplicate values. The definition of a key is slightly different when allowing duplicate search-keys. The keys the interior node $K_1, K_2, K_3, ... , K_n$ can be separated to \emph{new} and old keys. $K_i$ is the smallest new key that is part of the sub-tree linked with the $(i+1)$st pointer. If there is no new key associated with the $(i+1)$st pointer, $K_i$ is set to null. 

\begin{exmp}
	The example illustrated in Figure \ref{fig:BTreeBook} illustrates the case, in which the interior node in the right sub-tree $K_1$ is set to null. The leaf node that pointer $(1+1)$ is associated with contains only duplicate key values which is indicated by setting the interior node $K_1$ to null. The search-key in the root node is set to $17$ because it is the lowest $new$ key in the right sub-tree. Since $13.2$ is already in the left sub-tree, the duplicate search-key in the right sub-tree cannot be the key in the root. \\
	If e.g. $14.2$ would have been added to the tree, the leaves must be reordered, since the $B^+$ tree property that all leaves are ordered from left to right would be hurt.  
\end{exmp}
\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}[
	scale=0.7,
	every node/.style={outer sep=0pt, transform shape, font=\scriptsize},
	every matrix/.style={cells={scale=0.7}},
	]
	% root node
	\xyshift{-20mm}{0mm}{\btreeinodethree{root}{17}{}{}};
	
	%
	% intermediate nodes
	\xyshift{-50mm}{-15mm}{\btreeinodethree{n1}{7}{}{}{}}
	\xyshift{ 10mm}{-15mm}{\btreeinodethree{n2}{-}{37}{43}}
	%
	% connecting root to intermediate level nodes
	\foreach \x in {1,2} { \btreelink{root-\x}{n\x} }
	%
	% leaf nodes
	\xyshift{-90mm}{-30mm}{\btreelnodethree{n11}{2.5}{3}{6.1}}
	\xyshift{-60mm}{-30mm}{\btreelnodethree{n12}{7}{13.2}{}}
	\xyshift{-30mm}{-30mm}{\btreelnodethree{n21}{13.2}{17}{23}}
	\xyshift{ 0mm}{-30mm}{\btreelnodethree{n22}{23}{23}{}}
	\xyshift{ 30mm}{-30mm}{\btreelnodethree{n23}{23}{38.9}{40}}
	\xyshift{ 60mm}{-30mm}{\btreelnodethree{n24}{43}{47.1}{}}
	%
	% connecting intermediate level to leaf nodes
	\foreach \x in {1,2}     { \btreelink{n1-\x}{n1\x} }
	\foreach \x in {1,2,3,4} { \btreelink{n2-\x}{n2\x} }
	%
	% leaf pointers
	\draw[btlink] ([yshift=+3pt] n11-c.east) -- ([yshift=+3pt] n12-a.west);
	\draw[btlink] ([yshift=-3pt] n12-a.west) -- ([yshift=-3pt] n11-c.east);
	\draw[btlink] ([yshift=+3pt] n12-c.east) -- ([yshift=+3pt] n21-a.west);
	\draw[btlink] ([yshift=-3pt] n21-a.west) -- ([yshift=-3pt] n12-c.east);
	\draw[btlink] ([yshift=+3pt] n21-c.east) -- ([yshift=+3pt] n22-a.west);
	\draw[btlink] ([yshift=-3pt] n22-a.west) -- ([yshift=-3pt] n21-c.east);
	\draw[btlink] ([yshift=+3pt] n22-c.east) -- ([yshift=+3pt] n23-a.west);
	\draw[btlink] ([yshift=-3pt] n23-a.west) -- ([yshift=-3pt] n22-c.east);
	\draw[btlink] ([yshift=+3pt] n23-c.east) -- ([yshift=+3pt] n24-a.west);
	\draw[btlink] ([yshift=-3pt] n24-a.west) -- ([yshift=-3pt] n23-c.east);
	%

	
	\end{tikzpicture}
	\vspace{2mm}
	\caption{Duplicate handling proposed in \cite{BTreeBook}.}
	\label{fig:BTreeBook}
\end{figure}


\subsubsection{Advantages and Disadvantages}
\paragraph{$(+)$}
\begin{itemize}  
	\item  The deletion of the oldest duplicate search-key in the tree would be equally fast as with no duplicate search-keys, since the oldest key is the leftmost of all its duplicates. 
	\item  The \emph{neighbor}$(v,T)$ operation is equally fast, after $v$ has been found, as with no duplicate values. 
\end{itemize}
\paragraph{$(-)$}
\begin{itemize}  
	\item  The right sub-tree may also contain keys that are lower than the root key. Therefore the neighbour leaves must be checked as well when searching for a particular key. 
	\item In some cases the leaves have to be reordered.
	\item In case of duplicate values the neighbour leaves has to be checked as well to find the insertion point for a new key.
\end{itemize}


\subsection{Comparison of the Methods for Duplicate Handling}

The comparison of the four above described methods especially focuses on how they meet the requirements for the operations described in Section \ref{sec:Op}.\\
First of all, the \emph{Create unique Key} approach can not be used for the implementation. It does not provide a solution for handling duplicate search-keys, it just avoids to handle duplicates by creating a new unique key.\\
The \emph{Associated List} method described in Section \ref{Associated List} can be implemented differently, either using an array, a linked list or a doubly linked list. If it is implemented using an associated array the \emph{neighbor}$(v,T)$ operation is faster the more duplicate values are added to the associated lists. Further, the deletion and the insertion of a value to or from an existing list can be done in $O(1)$. But since the size of the array cannot be dynamically allocated, the memory needs to be reallocated if the array capacity has been achieved. This is very expensive. Using a linked list uses more memory since every temperature stored in the linked list needs more pointer and the insertion method is slower than if a array is used. The doubly linked list can provide a efficient insertion and deletion to the linked list but it uses even more pointer. Therefore, the \emph{Associated List} method is not useful if memory is short. In this case, memory is an important issue, the more memory the $B^+$ tree needs the smaller the time window $W$ can be to still be kept in main memory. \\
The other two methods: the \emph{Additional Leaves without a Parent} described in \ref{Additional Leaves} and the \emph{Null Values in Interior Nodes} described in Section \ref{Null Values} are more space efficient. Both methods need more or less the same amount of memory if they allow duplicates in the $B^+$ tree than if they would not. The \emph{neighbor}$(v,T)$ operation is in both methods equally fast, since the leaves contain all records ordered from left to right, no matter if they have a duplicate search-key or not.\emph{neighbor}$(v,T)$ operation. The deletion of a duplicate search-key, which must be done when the shift$(\bar{t}, v)$ method is called and the time window $W$ is full, is more or less equally fast, except for some special cases discussed in the following. In both methods the oldest duplicate search-key is always the leftmost of all equal search-keys. But if a key $k$ must be deleted that does not have a duplicate search-key but is still part of a node that contains duplicate search-keys, the deletion takes longer in both methods. Since all the duplicates in the left neighbour leaves that occur in the same leaf as $k$ have to be checked before. Another special case is when the leaves need to be reordered after a deletion. This may just be necessary if the method \emph{Null Values in Interior Nodes} is used. For example if $14$ is added to the tree illustrated in Figure \ref{fig:BTreeBook} the keys in the leaves would not be ordered from left to right any more. Since another $13.2$ search key is part of the right sub-tree. Therefore, the records in the leaves must be reordered to get a right order again.\\
The main difference between the last both methods is the insertion and search of a record. A new record is inserted when the shift$(\bar{t}, v)$ method is called. In both methods the insertion of a record that has a key that already occurs in the tree, in this case it is a temperature value $v$ that already exists in time window $W$, is depended on the number of duplicates that are already in the tree. The first potential leaf $L_p$ is found by searching the insertion point for a new record, assuming that the tree can be searched using the $B^+$ properties listed in Section \ref{structureBtree}. After identifying $L_p$ the \emph{Null Values in Interior Nodes} method must check all the right neighbour leaves of $L_p$, until the last duplicate is found or until a bigger search-key is found. If a bigger search-key is found, it is clear that no other duplicate search-key can occur on the further right part of the tree. After the insertion point is identified the new record can be inserted. The same principle is used in the \emph{Additional Leaves without a Parent} method, but if the right neighbour leaf is not parent-less it is directly clear that the insertion point must be before. \\Both methods are at least equally space efficient as a $B^+$ tree with no duplicate values. In the case a new parent-less leaf has to be inserted, using the \emph{Additional Leaves without a Parent} method, the tree uses even less space than it would with no duplicates, since the pointer from the parent to its child node does not exist. \\\\
To conclude, the first method \emph{Create unique Key} is impractical, since it does not handle duplicate search-keys. The second method \emph{Associated List} can have an efficient \emph{neighbor}$(v,T)$ operation but is altogether impractical in terms of space complexity. 
The last both methods have a equally fast \emph{neighbor}$(v,T)$ operation, after the value $v$ has already been found, as with no duplicate values. But with both methods a deletion, a search or an insertion can take longer than with no duplicate values in some special cases. Any common and special case must be handled before a new value arrives in time window $W$. Therefore, the time window $W$ can be just as large as the $B^+$ tree is able to handle a special case in time. \\
Since special cases e.g. a reordering of leaves is not necessary with the method \emph{Additional Leaves without a Parent Node} this approach is implemented because it meets the requirements the best. 


\chapter{Implementation}
\label{sec:Implementation}



\chapter{Evaluation}
\label{sec:Experimental}
\section{Experimental Setup}
\section{Results}
\section{Discussion}

\chapter{Summary and Conclusion}
\label{sec:Summary}
"The conclusion (10 to 12 per cent of the whole research thesis) does not only summarize the whole research thesis, but it also evaluates the results of the scientific inquiry. Do the results confirm or reject previously formulated hypotheses? The conclusion draws both theoretical and practical lessons that could be used in future analyses. These lessons are to be embedded as
2
recommendations for the research community and for policy-makers (note: policy relevance instead of policy prescriptive). In addition, the conclusion gives insights for further research."

\begin{thebibliography}{99}
	\bibliographystyle{alpha}
	
	\bibitem{BScT} K. Wellenzohn, M. Böhlen, A. Dignos, J. Gamper, and H. Mitterer: \emph{Continuous imputation of missing values in highly correlated streams of time series data}; Unpublished, 2016.
	
	\bibitem{OnlineAmnesicAppr} Themistoklis Palapanas, Michail Vlachos, Eamonn Keogh, Dimitrios Gunopulos, Wagner Truppel: \emph{Online Amnesic Approximation of Streaming Time Series}; University of California, Riverside, USA, 2004. \url{http://www.cs.ucr.edu/~eamonn/ICDM_2004.pdf}

	\bibitem{BTreeBook} Hector Garcia-Molina, Jeffrey D. Ullman, Jennifer Widom: \emph{Database Systems - The Complete Book}; ISBN 0-13-031995-3, 2002 by Prentice Hall
		
	



\end{thebibliography}






\end{document}
